![Python](https://img.shields.io/badge/Python-3.10-blue)
![ML](https://img.shields.io/badge/MachineLearning-Project-green)
![XAI](https://img.shields.io/badge/XAI-SHAP%20%7C%20DiCE-orange)

# ğŸ“Š Explainable Credit Default Prediction (SHAP + DiCE)

## ğŸ“Œ Overview
This project explores explainable machine learning for credit card default prediction using two complementary XAI approaches:

- SHAP for feature attribution (Logistic Regression model)
- DiCE for counterfactual explanations (XGBoost model)

The goal is to understand both:
1. Why a prediction was made
2. How a prediction could change

---

## ğŸ¯ Objectives
- Train machine learning models for credit default prediction
- Compare explanation methods across models
- Interpret feature importance globally and locally
- Generate counterfactual scenarios to understand decision boundaries

---

## ğŸ“‚ Project Structure
```
â”œâ”€â”€ SHAP_for_Credit_Card_Default.ipynb
â”œâ”€â”€ DiCE_for_Credit_Card_Default.ipynb
â””â”€â”€ README.md
```

---

## ğŸ§  Methodology

### SHAP â€” Model Interpretation (Logistic Regression)
- Feature importance ranking
- Global summary plot
- Individual prediction explanation
- Analysis of feature impact direction

---

### DiCE â€” Counterfactual Explanations (XGBoost)
- Generates alternative feature values
- Shows minimal changes required to flip prediction
- Demonstrates decision boundary behavior
- Provides actionable scenario analysis

---

## ğŸ” Why Two Models?

Different explanation methods work better with different model types.

| Model | Strength |
|------|--------|
Logistic Regression | Interpretable baseline |
XGBoost | Strong nonlinear modeling |

Using both helps compare:
- linear vs nonlinear decision boundaries
- attribution vs counterfactual explanations

---

## ğŸ›  Tech Stack
- Python
- Scikit-learn
- XGBoost
- SHAP
- DiCE
- Pandas
- NumPy
- Matplotlib

---

## ğŸ“Š Dataset
UCI Machine Learning Repository  
Default of Credit Card Clients Dataset

---

## ğŸ§  Key Learning Outcomes
- Understanding model transparency techniques
- Comparing explanation paradigms
- Interpreting model decision logic
- Evaluating prediction reliability

---

## ğŸ‘¤ Author
Jinhee Kim
M.S. Artificial Intelligence Student  
